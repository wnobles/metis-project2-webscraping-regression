{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping With BeautifulSoup and Selenium\n",
    "\n",
    "We'll begin the web scraping process by importing necessary libraries and packages, specifically using web scraping tools BeautifulSoup and Selenium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pickle\n",
    "import time, os\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import os.path\n",
    "from os import path\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36'}\n",
    "\n",
    "url = 'https://www.totalwine.com/spirits/scotch/blended-scotch/johnnie-walker-blue-year-of-the-ox/p/234446750?s=1006&igrules=true'\n",
    "response = requests.get(url, headers=headers)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(url)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code  #200 = success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping a single page\n",
    "\n",
    "We'll first gather the attributes we wish to obtain for a single page from [Total Wine](https://www.totalwine.com/), and then we'll write a function that can be used to obtain this same information for each bottle of whiskey. We want to get the following information to put into a table (i.e. dataframe):\n",
    "* Whiskey name\n",
    "* Rating\n",
    "* Rating source\n",
    "* User rating\n",
    "* Number of reviews\n",
    "* Price\n",
    "* Brand\n",
    "* Country\n",
    "* State\n",
    "* Spirit type\n",
    "* Taste\n",
    "\n",
    "#### Whiskey Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = soup.find('h1').text\n",
    "name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    rating = soup.find('div', class_='redBadgeNumber__DZXSWqnj').text\n",
    "except:\n",
    "    rating = None\n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rating Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    source = soup.find('div', class_='redBadgeSource__1hMXdJ5Z').text.strip()\n",
    "except:\n",
    "    source = None\n",
    "source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    user_rating = soup.find(class_='bv_avgRating_component_container notranslate').text\n",
    "except:\n",
    "    user_rating = None\n",
    "user_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = soup.find(class_='bv_numReviews_component_container').text\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    price = soup.find(id='edlpPrice').text\n",
    "except:\n",
    "    price = None\n",
    "price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = soup.find(class_='detailsTableText__1SvcRdYn').findChild().text\n",
    "brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = soup.find(text='COUNTRY').findNext().text\n",
    "country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    state = soup.find(text='STATE').findNext().text\n",
    "except:\n",
    "    state = None\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spirit type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spirit_type = soup.find(text='SPIRITS TYPE').findNext().text\n",
    "spirit_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    taste = soup.find(text='TASTE').findNext().text\n",
    "except:\n",
    "    taste = None\n",
    "taste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create helper functions to parse strings into appropriate data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def money_to_float(moneystring):\n",
    "    moneystring = moneystring.replace('$', '').replace(',', '')\n",
    "    return float(moneystring)\n",
    "\n",
    "def to_taste(taste_string):\n",
    "    taste = taste_string.split(\",\")\n",
    "    return taste\n",
    "\n",
    "def name_to_title(whiskey_name):\n",
    "    whiskey_name = whiskey_name.title()\n",
    "    return whiskey_name\n",
    "\n",
    "def format_number_of_reviews(num_reviews):\n",
    "    num_reviews = num_reviews.replace('\\xa0(', '').replace(')', '')\n",
    "    return int(num_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = money_to_float(price)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taste = to_taste(taste)\n",
    "taste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = name_to_title(name)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = format_number_of_reviews(reviews)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the items from a single page in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = ['whiskey_name', 'rating', 'rating_source', 'user_rating',\n",
    "           'num_reviews', 'price', 'brand', 'country',\n",
    "           'state', 'spirit_type', 'taste']\n",
    "\n",
    "whiskey_data = []\n",
    "whiskey_dict = dict(zip(headers, [name, rating, source, user_rating,\n",
    "                                  reviews, price, brand, country,\n",
    "                                  state, spirit_type, taste]))\n",
    "\n",
    "whiskey_data.append(whiskey_dict)\n",
    "whiskey_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping multiple pages\n",
    "\n",
    "First, gather page URLs for each page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_urls = []\n",
    "for num in range(1, 11):\n",
    "    page_urls.append(\"https://www.totalwine.com/spirits/whiskey/c/9238919?viewall=true&page={}&pageSize=120&spiritsvolume=Standard%20Size%20750%20ml&aty=1,1,1,1\".format(num))\n",
    "\n",
    "page_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, visit the first page to gather the links for each bottle on a single page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36'}\n",
    "\n",
    "response = requests.get(page_urls[1], headers=headers)\n",
    "page = response.text\n",
    "soup = BeautifulSoup(page)\n",
    "\n",
    "driver = webdriver.Chrome(chromedriver)\n",
    "driver.get(page_urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.page_source[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalwine_url = 'https://totalwine.com'\n",
    "\n",
    "# get the anchor tags\n",
    "anchors = soup.find(class_='grid__1eZnNfL-').find_all('a')\n",
    "\n",
    "# get the hrefs\n",
    "hrefs = [totalwine_url + a.get('href') for a in anchors]\n",
    "hrefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each bottle of whiskey contains a duplicate and then another link to the same bottle, but with '&tab3' appended. We need to remove the link with the appended characters and then remove the duplicate value to get a list with unique links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove links with the appended characters\n",
    "[hrefs.remove(link) for link in hrefs if '&tab=3' in link]\n",
    "hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "hrefs = list(set(hrefs))\n",
    "hrefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put it all in a function so that for each results page we visit we can gather the links for each bottle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_links(page_url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36'}\n",
    "\n",
    "    response = requests.get(page_url, headers=headers)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page)\n",
    "    \n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.get(page_url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    totalwine_url = 'https://totalwine.com'\n",
    "\n",
    "    # get the anchor tags\n",
    "    anchors = soup.find(class_='grid__1eZnNfL-').find_all('a')\n",
    "\n",
    "    # get the hrefs\n",
    "    hrefs = [totalwine_url + a.get('href') for a in anchors]\n",
    "    \n",
    "    # remove links with the appended characters\n",
    "    [hrefs.remove(link) for link in hrefs if '&tab=3' in link]\n",
    "    \n",
    "    # remove duplicates\n",
    "    hrefs = list(set(hrefs))\n",
    "    \n",
    "    return hrefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's gather the links for each of the 120 bottles on each of the first 10 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottles_list = []\n",
    "for url in page_urls:\n",
    "    bottles_list.append(get_page_links(url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottles_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten the list of links\n",
    "bottles_list = [link for sublist in bottles_list for link in sublist]\n",
    "len(bottles_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the list. We had to use Selenium since information on the Total Wine website is dynamic (i.e. it changes with new products, reviews, etc.), so it's a good idea to save the list we scraped so that we minimize duplicates when scraping pages for individual whiskeys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the bottles list\n",
    "filename = 'bottles.pkl'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(bottles_list,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Lastly, we'll combine all the steps from the beginning where we scraped information from a single page into a function, so that we can loop through each of the pages in our `bottles_list` and scrape information on each bottle and store it in a list to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_whiskey_dict(link):\n",
    "    '''\n",
    "    From TotalWine link stub, request bottle html, parse with BeautifulSoup, and\n",
    "    collect \n",
    "        - whiskey name \n",
    "        - rating\n",
    "        - rating source \n",
    "        - user rating\n",
    "        - number of reviews\n",
    "        - price\n",
    "        - brand\n",
    "        - country\n",
    "        - state\n",
    "        - spirit type\n",
    "        - taste\n",
    "    Return information as a dictionary.\n",
    "    '''\n",
    "    \n",
    "    columns = ['whiskey_name', 'rating', 'rating_source', 'user_rating',\n",
    "           'num_reviews', 'price', 'brand', 'country',\n",
    "           'state', 'spirit_type', 'taste']\n",
    "    \n",
    "    #Request HTML and parse\n",
    "    user_agent = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36'}\n",
    "    response = requests.get(link, headers=user_agent)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page)\n",
    "\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.get(link)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    # Get whiskey name\n",
    "    name = soup.find('h1').text\n",
    "    name = name_to_title(name)\n",
    "\n",
    "    # Get rating\n",
    "    try:\n",
    "        rating = int(soup.find('div', class_='redBadgeNumber__DZXSWqnj').text)\n",
    "    except:\n",
    "        rating = None\n",
    "    \n",
    "    # Get rating source\n",
    "    try:\n",
    "        source = soup.find('div', class_='redBadgeSource__1hMXdJ5Z').text.strip()\n",
    "    except:\n",
    "        source = None\n",
    "\n",
    "    # Get user rating\n",
    "    try:\n",
    "        user_rating = float(soup.find(class_='bv_avgRating_component_container notranslate').text)\n",
    "    except:\n",
    "        user_rating = None\n",
    "\n",
    "    # Get number of reviews\n",
    "    try:\n",
    "        reviews = soup.find(class_='bv_numReviews_component_container').text\n",
    "        reviews = format_number_of_reviews(reviews)\n",
    "    except:\n",
    "        reviews = None\n",
    "    \n",
    "    # Get price\n",
    "    try:\n",
    "        price = soup.find(id='edlpPrice').text\n",
    "        price = money_to_float(price)\n",
    "    except:\n",
    "        price = None\n",
    "    \n",
    "    # Get brand\n",
    "    brand = soup.find(class_='detailsTableText__1SvcRdYn').findChild().text\n",
    "    \n",
    "    # Get country\n",
    "    country = soup.find(text='COUNTRY').findNext().text\n",
    "    \n",
    "    # Get state\n",
    "    try:\n",
    "        state = soup.find(text='STATE').findNext().text\n",
    "    except:\n",
    "        state = None\n",
    "    \n",
    "    # Get spirit type\n",
    "    spirit_type = soup.find(text='SPIRITS TYPE').findNext().text\n",
    "    \n",
    "    # Get taste\n",
    "    try:\n",
    "        taste = soup.find(text='TASTE').findNext().text\n",
    "        taste = to_taste(taste)\n",
    "    except:\n",
    "        taste = None\n",
    "    \n",
    "    # Create whiskey dictionary and return\n",
    "    whiskey_dict = dict(zip(columns, [name, rating, source, user_rating,\n",
    "                                  reviews, price, brand, country,\n",
    "                                  state, spirit_type, taste]))\n",
    "\n",
    "    return whiskey_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `bottles_list` from earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bottles_list\n",
    "bottles_filename = 'bottles.pkl'\n",
    "infile = open(bottles_filename,'rb')\n",
    "new_bottles_list = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "new_bottles_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'whiskeys.pkl'\n",
    "\n",
    "# check if we already have the file in the event that scraping was blocked by the website\n",
    "if path.exists(filename):\n",
    "    infile = open(filename,'rb')\n",
    "    whiskey_list = pickle.load(infile)\n",
    "    infile.close()\n",
    "else:\n",
    "    whiskey_list = []\n",
    "\n",
    "outfile = open(filename, 'wb')\n",
    "\n",
    "# loop through the list of all urls for whiskey bottles and scrape each page\n",
    "i = 1172\n",
    "while i < 1200:\n",
    "    try:\n",
    "        link = new_bottles_list[i]\n",
    "        whiskey_list.append(get_whiskey_dict(link))\n",
    "        i += 1\n",
    "    except:\n",
    "        pickle.dump(whiskey_list, outfile)\n",
    "        break\n",
    "        \n",
    "pickle.dump(whiskey_list, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check that our pickle is writing new entries to the file each time our scraping process is ended by the Total wine website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whiskey_filename = 'whiskeys.pkl'\n",
    "infile = open(whiskey_filename,'rb')\n",
    "new_whiskey_list = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "print(len(new_whiskey_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
