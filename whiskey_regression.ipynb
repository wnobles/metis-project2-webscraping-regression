{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "infile = open('whiskeys.pkl','rb')\n",
    "my_list = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(my_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 1199 entries for the 11 columns we scraped for our data set, but let's also check for duplicates based on the name of the whiskey since other columns containing information on the brand, country, etc. are likely to have repeating values that aren't actually duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the number of duplicate bottles\n",
    "df.duplicated(subset='whiskey_name').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the duplicate value\n",
    "df[df.duplicated(subset='whiskey_name') == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicate\n",
    "df.drop_duplicates(subset='whiskey_name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `whiskey_name` column, we see that for whiskeys that include an apostrophe and an *s* in the title, the *s* is capitalized. We can change that so that the bottle name is titled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['whiskey_name'] = df['whiskey_name'].str.replace(\"'S\", \"'s\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll check for null values and drop any `NaN` values from columns that will later be continuous features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['user_rating', 'num_reviews', 'price'], inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also fill `NaN` values with 0 from columns that will later be categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'rating_source':0, 'state':0, 'taste':0}\n",
    "df.fillna(value=values, inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is cleaned, we'll observe how the different features are related to one another, first in a heatmap and then in a pairplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(df.corr(), cmap=\"seismic\", vmin=-1, vmax=1, annot=True, ax=ax);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, height=1.5, aspect=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our data has some outliers that may affect our model, specifically with respect to price. We'll first look at the average price of a whiskey and the standard deviation. After, we can sort the values and remove any outliers to see if we can improve the correlation between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average price for a bottle of whiskey is about \\\\$140 with a standard deviation of about $857. Looking below at the dataframe, it may be helpful to remove bottles with a value over \\\\$1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['price'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.price > 1000].index, inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at our plots again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(df.corr(), cmap=\"seismic\", vmin=-1, vmax=1, annot=True, ax=ax);\n",
    "#plt.savefig('heatmap.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, height=2, aspect=1);\n",
    "#plt.savefig('pairplot.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df\n",
    "#df1['brand_counts'] = df.groupby(df.brand).transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['brand_counts'] = df1.groupby('brand')['brand'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.sort_values(by='brand_counts', ascending=False, inplace=True)\n",
    "df1.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(data=df1, x=\"brand_counts\", kde=True, color=\"red\")\n",
    "plt.xlabel(\"Bottles/Brand\", size=20)\n",
    "plt.ylabel(\"Count\", size=20)\n",
    "plt.title(\"Plot of Counts for Number of Bottles Produced Per Brand\", size=24)\n",
    "#g.set(xticks=[])\n",
    "#g.set_xticklabels(rotation=45)\n",
    "#plt.savefig('brand_frequency.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 1\n",
    "Build a linear model that uses only a constant term (a column of ones) to predict a continuous outcome (like domestic total gross). How can you interpret the results of this model? What does it predict? Make a plot of predictions against actual outcome. Make a histogram of residuals. How are the residuals distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target_mean'] = df['user_rating'].mean()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Choose the predictor variables, here all but the first which is the response variable\n",
    "# This model is analogous to the Y ~ X1 + X2 + X3 + X4 + X5 + X6 model\n",
    "X = df[['target_mean']]\n",
    "\n",
    "# Choose the response variable(s)\n",
    "y = df[['user_rating']]\n",
    "\n",
    "# Fit the model to the full dataset\n",
    "fit1 = lr.fit(X, y)\n",
    "\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(y, lr.predict(X), color='r')\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('Scatter Plot of Predicted vs Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_residuals = df[['user_rating']] - lr.predict(X)\n",
    "sns.histplot(data=y_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 2\n",
    "Repeat the process of challenge one, but also add one continuous (numeric) predictor variable. Also add plots of model prediction against your feature variable and residuals against feature variable. How can you interpret what's happening in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Choose the predictor variables, here all but the first which is the response variable\n",
    "# This model is analogous to the Y ~ X1 + X2 + X3 + X4 + X5 + X6 model\n",
    "X = df[['target_mean', 'price']]\n",
    "\n",
    "# Choose the response variable(s)\n",
    "y = df[['user_rating']]\n",
    "\n",
    "# Fit the model to the full dataset\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Print out the R^2 for the model against the full dataset\n",
    "lr.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(y, lr.predict(X), color='b')\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('Scatter Plot of Predicted vs Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_residuals = df[['user_rating']] - lr.predict(X)\n",
    "sns.histplot(data=y_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 3\n",
    "Repeat the process of Challenge 1, but add a categorical feature (like genre). You'll have to convert a column of text into a number of numerical columns (\"dummy variables\"). How can you interpret what's happening in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the predictor variables, here all but the first which is the response variable\n",
    "# This model is analogous to the Y ~ X1 + X2 + X3 + X4 + X5 + X6 model\n",
    "X = df[['target_mean', 'price', 'country']]\n",
    "\n",
    "# Choose the response variable(s)\n",
    "y = df[['user_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_variables = ['country']\n",
    "\n",
    "X_cat = df[cat_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "ohe.fit(X_cat) \n",
    "cats = ohe.transform(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ohe.get_feature_names(cat_variables)\n",
    "X_cat_df = pd.DataFrame(cats, columns=columns, index=X_cat.index)\n",
    "X_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont = df[['target_mean', 'price']]\n",
    "\n",
    "X_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_cont)\n",
    "X_scaled = ss.transform(X_cont)\n",
    "\n",
    "cont_columns = X_cont.columns\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=cont_columns, index=X_cont.index)\n",
    "\n",
    "X_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = pd.concat([X_cat_df, X_scaled_df], axis='columns')\n",
    "\n",
    "X_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_combined, y)\n",
    "\n",
    "y_pred = lr.predict(X_combined)\n",
    "\n",
    "y_pred\n",
    "\n",
    "lr.score(X_combined, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(y, y_pred, color='b')\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('Scatter Plot of Predicted vs Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_residuals = y - y_pred\n",
    "sns.histplot(data=y_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 4\n",
    "Enhance your model further by adding more features and/or transforming existing features. Think about how you build the model matrix and how to interpret what the model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first three predictor variables are continuous and the last three are categorical\n",
    "X = df[['target_mean', 'num_reviews', 'price', 'brand', 'country', 'spirit_type']]\n",
    "\n",
    "# Choose the response variable(s)\n",
    "y = df[['user_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_variables = ['brand', 'country', 'spirit_type']\n",
    "\n",
    "X_cat = df[cat_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "ohe.fit(X_cat) \n",
    "cats = ohe.transform(X_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ohe.get_feature_names(cat_variables)\n",
    "X_cat_df = pd.DataFrame(cats, columns=columns, index=X_cat.index)\n",
    "X_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cont = df[['target_mean', 'num_reviews', 'price']]\n",
    "\n",
    "X_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_cont)\n",
    "X_scaled = ss.transform(X_cont)\n",
    "\n",
    "cont_columns = X_cont.columns\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=cont_columns, index=X_cont.index)\n",
    "\n",
    "X_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = pd.concat([X_cat_df, X_scaled_df], axis='columns')\n",
    "\n",
    "X_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_combined, y)\n",
    "\n",
    "y_pred = lr.predict(X_combined)\n",
    "\n",
    "y_pred\n",
    "\n",
    "lr.score(X_combined, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(y, y_pred, color='b')\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('Scatter Plot of Predicted vs Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_residuals = y - y_pred\n",
    "sns.histplot(data=y_residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenge 5\n",
    "Fitting and checking predictions on the exact same data set can be misleading. Divide your data into two sets: a training and a test set (roughly 75% training, 25% test is a fine split). Fit a model on the training set, check the predictions (by plotting versus actual values) in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# The first three predictor variables are continuous and the last three are categorical\n",
    "X = df[['target_mean', 'num_reviews', 'price', 'brand', 'country', 'spirit_type']]\n",
    "\n",
    "# Choose the response variable(s)\n",
    "y = df[['user_rating']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_variables = ['brand', 'country', 'spirit_type']\n",
    "\n",
    "X_train_cat = X_train[cat_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "ohe.fit(X_train_cat) \n",
    "cats = ohe.transform(X_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns = ohe.get_feature_names(cat_variables)\n",
    "X_train_cat_df = pd.DataFrame(cats, columns=columns, index=X_train_cat.index)\n",
    "X_train_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_test_cat = X_test[['brand', 'country', 'spirit_type']]\n",
    "\n",
    "cats_test = ohe.transform(X_test_cat) # REMEMBER ONLY TRANSFORM ON TEST SET\n",
    "\n",
    "cat_columns = ohe.get_feature_names(['brand', 'country', 'spirit_type'])\n",
    "X_test_cat_df = pd.DataFrame(cats_test, columns=cat_columns, index=X_test_cat.index)\n",
    "X_test_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cont = X_train[['target_mean', 'num_reviews', 'price']]\n",
    "\n",
    "X_train_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_train_cont)\n",
    "X_train_scaled = ss.transform(X_train_cont)\n",
    "\n",
    "cont_columns = X_train_cont.columns\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=cont_columns, index=X_train_cont.index)\n",
    "\n",
    "X_train_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cont = X_test[['target_mean', 'num_reviews', 'price']]\n",
    "\n",
    "X_test_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.fit(X_test_cont)\n",
    "\n",
    "X_test_scaled = ss.transform(X_test_cont)\n",
    "\n",
    "cont_columns = X_test_cont.columns\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=cont_columns, index=X_test_cont.index)\n",
    "\n",
    "X_test_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = pd.concat([X_train_cat_df, X_train_scaled_df], axis='columns')\n",
    "\n",
    "X_train_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_combined = pd.concat([X_test_cat_df, X_test_scaled_df], axis='columns')\n",
    "\n",
    "X_test_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train_combined, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test_combined)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lr.score(X_test_combined, y_test) \n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score for the training set is greater than the test set, which means that the data is very overfit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_test_combined.columns\n",
    "\n",
    "coefficient_values = np.round(lr.coef_, 3)\n",
    "\n",
    "feats_values = list(zip(feature_names, coefficient_values)) \n",
    "\n",
    "sorted(feats_values, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(y_train, lr.predict(X_train_combined), color='b')\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title('Scatter Plot of Predicted vs Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate our features from our target\n",
    "\n",
    "X = df.loc[:,['num_reviews', 'price', 'brand', 'country', 'spirit_type']]\n",
    "\n",
    "y = df['user_rating']\n",
    "\n",
    "# create overall quality squared term, which we expect to \n",
    "# help based on the relationship we see in the pair plot \n",
    "X['price_squared'] = X['price'] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data 60 - 20 - 20 train/val/test\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "cat_variables = ['brand', 'country', 'spirit_type']\n",
    "X_train_cat = X_train[cat_variables]\n",
    "\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "ohe.fit(X_train_cat) \n",
    "cats = ohe.transform(X_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ohe.get_feature_names(cat_variables)\n",
    "X_train_cat_df = pd.DataFrame(cats, columns=columns, index=X_train_cat.index)\n",
    "X_train_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cat = X_test[['brand', 'country', 'spirit_type']]\n",
    "\n",
    "cats_test = ohe.transform(X_test_cat) # REMEMBER ONLY TRANSFORM ON TEST SET\n",
    "\n",
    "cat_columns = ohe.get_feature_names(['brand', 'country', 'spirit_type'])\n",
    "X_test_cat_df = pd.DataFrame(cats_test, columns=cat_columns, index=X_test_cat.index)\n",
    "X_test_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_cat = X_val[['brand', 'country', 'spirit_type']]\n",
    "\n",
    "cats_val = ohe.transform(X_val_cat) # REMEMBER ONLY TRANSFORM ON TEST SET\n",
    "\n",
    "cat_columns = ohe.get_feature_names(['brand', 'country', 'spirit_type'])\n",
    "X_val_cat_df = pd.DataFrame(cats_val, columns=cat_columns, index=X_val_cat.index)\n",
    "X_val_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cont = X_train[['num_reviews', 'price']]\n",
    "\n",
    "X_train_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "ss.fit(X_train_cont)\n",
    "X_train_scaled = ss.transform(X_train_cont)\n",
    "\n",
    "cont_columns = X_train_cont.columns\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=cont_columns, index=X_train_cont.index)\n",
    "\n",
    "X_train_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cont = X_test[['num_reviews', 'price']]\n",
    "\n",
    "X_test_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = ss.transform(X_test_cont)\n",
    "\n",
    "cont_columns = X_test_cont.columns\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=cont_columns, index=X_test_cont.index)\n",
    "\n",
    "X_test_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_cont = X_val[['num_reviews', 'price']]\n",
    "\n",
    "X_val_cont.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = ss.transform(X_val_cont)\n",
    "\n",
    "cont_columns = X_test_cont.columns\n",
    "X_val_scaled_df = pd.DataFrame(X_val_scaled, columns=cont_columns, index=X_val_cont.index)\n",
    "\n",
    "X_val_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_combined = pd.concat([X_train_cat_df, X_train_scaled_df], axis='columns')\n",
    "\n",
    "X_train_combined.head()\n",
    "\n",
    "X_train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_combined = pd.concat([X_test_cat_df, X_test_scaled_df], axis='columns')\n",
    "\n",
    "X_test_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_combined = pd.concat([X_val_cat_df, X_val_scaled_df], axis='columns')\n",
    "\n",
    "X_val_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cross validation, find the best alpha, refit the model on all the data with that alpha\n",
    "\n",
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "\n",
    "lasso_model = LassoCV(alphas = alphavec, cv=5)\n",
    "lasso_model.fit(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the best alpha value it found - not far from the value\n",
    "# selected using simple validation\n",
    "lasso_model.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the (standardized) coefficients found\n",
    "# when it refit using that best alpha\n",
    "list(zip(X_train.columns, lasso_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set using the new model\n",
    "test_set_pred = lasso_model.predict(X_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model.score(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model.score(X_test_combined, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['brand'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"rating\", y=\"user_rating\", data=df, order=2, kind=\"reg\");\n",
    "plt.xlabel(\"Critic Rating\", size=20)\n",
    "plt.ylabel(\"User Rating\", size=20)\n",
    "plt.title(\"User Rating vs. Critic Rating\", size=24, y=1.25)\n",
    "#plt.savefig('user_rating_vs_rating.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(df, x='country', binwidth=8, hue='country')\n",
    "plt.xlabel(\"Country\", size=20)\n",
    "plt.ylabel(\"Count\", size=20)\n",
    "plt.title(\"Number of Whiskeys Manufactured by Country\", size=24)\n",
    "g.set_xticklabels(rotation=45)\n",
    "#plt.savefig('whiskeys_by_country.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
